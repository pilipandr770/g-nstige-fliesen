"""
–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –±–ª–æ–≥–∞ Aparici
"""

import requests
from bs4 import BeautifulSoup
import re

def analyze_blog_structure():
    url = 'https://www.aparici.com/de/blog'
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    print(f"üîç –ê–Ω–∞–ª–∏–∑ –±–ª–æ–≥–∞: {url}\n")
    
    try:
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        print("=" * 60)
        print("1. –í—Å–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å—Ç–∞—Ç—å–∏ –±–ª–æ–≥–∞:")
        print("=" * 60)
        
        blog_links = soup.find_all('a', href=re.compile(r'/blog/'))
        
        unique_links = {}
        for link in blog_links:
            href = link.get('href')
            if href and href not in unique_links and len(href.split('/')) > 3:  # –ù–µ –≥–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –±–ª–æ–≥–∞
                unique_links[href] = link.get_text(strip=True)
        
        print(f"–ù–∞–π–¥–µ–Ω–æ {len(unique_links)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π\n")
        
        for i, (href, text) in enumerate(list(unique_links.items())[:10], 1):
            print(f"{i}. {href}")
            print(f"   –ó–∞–≥–æ–ª–æ–≤–æ–∫: {text[:80]}")
            print()
        
        print("\n" + "=" * 60)
        print("2. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–∞—Ä—Ç–æ—á–µ–∫ —Å—Ç–∞—Ç–µ–π:")
        print("=" * 60)
        
        # –ò—â–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã —Å—Ç–∞—Ç–µ–π
        possible_containers = soup.find_all(['article', 'div'], class_=re.compile(r'blog|post|article|card', re.I))
        
        print(f"–ù–∞–π–¥–µ–Ω–æ {len(possible_containers)} –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤\n")
        
        for i, container in enumerate(possible_containers[:5], 1):
            print(f"–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä {i}:")
            print(f"  Tag: {container.name}")
            print(f"  Classes: {container.get('class', [])}")
            
            # –ò—â–µ–º —Å—Å—ã–ª–∫—É
            link = container.find('a', href=re.compile(r'/blog/'))
            if link:
                print(f"  –°—Å—ã–ª–∫–∞: {link.get('href')}")
            
            # –ò—â–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            title = container.find(['h1', 'h2', 'h3', 'h4'])
            if title:
                print(f"  –ó–∞–≥–æ–ª–æ–≤–æ–∫: {title.get_text(strip=True)[:60]}")
            
            # –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            img = container.find('img')
            if img:
                src = img.get('src') or img.get('data-src')
                print(f"  –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {src[:60] if src else 'no src'}")
            
            # –ò—â–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ/–∫–æ–Ω—Ç–µ–Ω—Ç
            paragraphs = container.find_all('p')
            if paragraphs:
                print(f"  –ü–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {len(paragraphs)}")
            
            print()
        
        print("\n" + "=" * 60)
        print("3. –í—Å–µ –∫–ª–∞—Å—Å—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ (–ø–µ—Ä–≤—ã–µ 30):")
        print("=" * 60)
        
        all_classes = set()
        for tag in soup.find_all(class_=True):
            classes = tag.get('class', [])
            all_classes.update(classes)
        
        sorted_classes = sorted(all_classes)
        for cls in sorted_classes[:30]:
            print(f"   - {cls}")
        
        print("\n" + "=" * 60)
        print("4. –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ:")
        print("=" * 60)
        
        images = soup.find_all('img')
        print(f"–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(images)}\n")
        
        for i, img in enumerate(images[:10], 1):
            src = img.get('src') or img.get('data-src')
            alt = img.get('alt', 'no alt')
            classes = img.get('class', [])
            
            print(f"{i}. Src: {src[:60] if src else 'no src'}")
            print(f"   Alt: {alt[:50]}")
            print(f"   Classes: {classes}")
            
            parent = img.parent
            if parent and parent.name == 'a':
                print(f"   –í —Å—Å—ã–ª–∫–µ: {parent.get('href', 'no href')[:60]}")
            print()
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    analyze_blog_structure()
