"""
–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å—Ç—Ä–∞–Ω–∏—Ü La Fabbrica
"""
import requests
from bs4 import BeautifulSoup
import re

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
}

base_url = 'https://www.lafabbrica.it'

print("="*80)
print("–î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –°–¢–†–£–ö–¢–£–†–´ LA FABBRICA")
print("="*80)

# 1. –ö–û–õ–õ–ï–ö–¶–ò–ò
print("\nüì¶ –ö–û–õ–õ–ï–ö–¶–ò–ò (/de/collections)")
print("-"*80)
try:
    response = requests.get(base_url + '/de/collections', headers=headers, timeout=15)
    soup = BeautifulSoup(response.content, 'html.parser')
    
    # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
    collection_links = soup.find_all('a', href=re.compile(r'/collection/'))
    
    print(f"–ù–∞–π–¥–µ–Ω–æ {len(collection_links)} —Å—Å—ã–ª–æ–∫ –Ω–∞ –∫–æ–ª–ª–µ–∫—Ü–∏–∏")
    
    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    unique_collections = {}
    for link in collection_links:
        href = link.get('href')
        if href not in unique_collections:
            unique_collections[href] = link
    
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–ª–ª–µ–∫—Ü–∏–π: {len(unique_collections)}")
    
    for i, (href, link) in enumerate(list(unique_collections.items())[:5], 1):
        print(f"\n–ö–æ–ª–ª–µ–∫—Ü–∏—è {i}:")
        print(f"  URL: {href}")
        
        # –ù–∞–∑–≤–∞–Ω–∏–µ
        title = link.get_text(strip=True)
        print(f"  –¢–µ–∫—Å—Ç: {title[:50]}")
        
        # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        img = link.find('img')
        if not img and link.parent:
            img = link.parent.find('img')
        
        if img:
            print(f"  –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {img.get('src')}")
            print(f"  Alt: {img.get('alt')}")
        
        # –ö–ª–∞—Å—Å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
        parent = link.parent
        if parent:
            print(f"  –†–æ–¥–∏—Ç–µ–ª—å: {parent.name}, –∫–ª–∞—Å—Å: {parent.get('class')}")
            
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

# 2. –ü–†–û–ï–ö–¢–´
print("\n\nüèóÔ∏è –ü–†–û–ï–ö–¢–´ (/de/projects)")
print("-"*80)
try:
    response = requests.get(base_url + '/de/projects', headers=headers, timeout=15)
    soup = BeautifulSoup(response.content, 'html.parser')
    
    # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –ø—Ä–æ–µ–∫—Ç—ã
    project_links = soup.find_all('a', href=re.compile(r'/project/'))
    
    unique_projects = {}
    for link in project_links:
        href = link.get('href')
        if href not in unique_projects:
            unique_projects[href] = link
    
    print(f"–ù–∞–π–¥–µ–Ω–æ {len(unique_projects)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤")
    
    for i, (href, link) in enumerate(list(unique_projects.items())[:5], 1):
        print(f"\n–ü—Ä–æ–µ–∫—Ç {i}:")
        print(f"  URL: {href}")
        
        # –ù–∞–∑–≤–∞–Ω–∏–µ
        title = link.get_text(strip=True)
        if not title:
            # –ò—â–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Ä—è–¥–æ–º
            parent = link.parent
            if parent:
                h_tag = parent.find(['h1', 'h2', 'h3', 'h4'])
                if h_tag:
                    title = h_tag.get_text(strip=True)
        
        print(f"  –ù–∞–∑–≤–∞–Ω–∏–µ: {title[:50]}")
        
        # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        img = link.find('img')
        if not img and link.parent:
            img = link.parent.find('img')
        
        if img:
            print(f"  –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {img.get('src')}")
            
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

# 3. –ë–õ–û–ì
print("\n\nüì∞ –ë–õ–û–ì (/de/blog)")
print("-"*80)
try:
    response = requests.get(base_url + '/de/blog', headers=headers, timeout=15)
    soup = BeautifulSoup(response.content, 'html.parser')
    
    # –ò—â–µ–º —Å—Ç–∞—Ç—å–∏ –±–ª–æ–≥–∞
    blog_links = soup.find_all('a', href=re.compile(r'/blog/.+'))
    
    unique_blogs = {}
    for link in blog_links:
        href = link.get('href')
        # –ò—Å–∫–ª—é—á–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        if href.count('/') > 3 and href not in unique_blogs:
            unique_blogs[href] = link
    
    print(f"–ù–∞–π–¥–µ–Ω–æ {len(unique_blogs)} —Å—Ç–∞—Ç–µ–π –±–ª–æ–≥–∞")
    
    for i, (href, link) in enumerate(list(unique_blogs.items())[:5], 1):
        print(f"\n–°—Ç–∞—Ç—å—è {i}:")
        print(f"  URL: {href}")
        
        # –ù–∞–∑–≤–∞–Ω–∏–µ
        title = link.get_text(strip=True)
        print(f"  –ù–∞–∑–≤–∞–Ω–∏–µ: {title[:60]}")
        
        # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        img = link.find('img')
        if not img and link.parent:
            img = link.parent.find('img')
        
        if img:
            print(f"  –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {img.get('src')}")
            
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

print("\n" + "="*80)
